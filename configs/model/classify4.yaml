_target_: src.models.classify4_module.Classify4LitModule

name: vit_large_r50_s32_384

# only input 224

#['vit_base_patch16_224',
# 'vit_base_patch32_224',
# 'vit_large_patch16_224',
# 'vit_large_r50_s32_224',
# 'vit_small_patch16_224',
# 'vit_small_patch32_224',
# 'vit_small_r26_s32_224',
# 'vit_tiny_patch16_224',
# 'vit_tiny_r_s16_p8_224']


# only input 384

#['beit_base_patch16_384',
# 'beit_large_patch16_384',
# 'cait_m36_384',
# 'cait_s24_384',
# 'cait_s36_384',
# 'cait_xs24_384',
# 'cait_xxs24_384',
# 'cait_xxs36_384',
# 'convnext_base_384_in22ft1k',
# 'convnext_large_384_in22ft1k',
# 'convnext_xlarge_384_in22ft1k',
# 'deit_base_distilled_patch16_384',
# 'deit_base_patch16_384',
# 'levit_384',
# 'resnetv2_152x2_bit_teacher_384',
# 'swin_base_patch4_window12_384',
# 'swin_base_patch4_window12_384_in22k',
# 'swin_large_patch4_window12_384',
# 'swin_large_patch4_window12_384_in22k',
# 'vit_base_patch16_384',
# 'vit_base_patch32_384',
# 'vit_base_r50_s16_384',
# 'vit_large_patch16_384',
# 'vit_large_patch32_384',
# 'vit_large_r50_s32_384',
# 'vit_small_patch16_384',
# 'vit_small_patch32_384',
# 'vit_small_r26_s32_384',
# 'vit_tiny_patch16_384',
# 'vit_tiny_r_s16_p8_384',
# 'xcit_large_24_p8_384_dist',
# 'xcit_large_24_p16_384_dist',
# 'xcit_medium_24_p8_384_dist',
# 'xcit_medium_24_p16_384_dist',
# 'xcit_nano_12_p8_384_dist',
# 'xcit_nano_12_p16_384_dist',
# 'xcit_small_12_p8_384_dist',
# 'xcit_small_12_p16_384_dist',
# 'xcit_small_24_p8_384_dist',
# 'xcit_small_24_p16_384_dist',
# 'xcit_tiny_12_p8_384_dist',
# 'xcit_tiny_12_p16_384_dist',
# 'xcit_tiny_24_p8_384_dist',
# 'xcit_tiny_24_p16_384_dist']


lr: 1e-4
weight_decay: 0.0005
t_max: 10
min_lr: 1e-6
T_0: 15
T_mult: 2
eta_min: 1e-6
pretrained: True
scheduler: 'ReduceLROnPlateau'
factor: 0.5
patience: 3
eps: 1e-8
loss_weight: 0.25
threshold: 0.8
num_sample: 10
key: 'prob'
sampling: 'trust'
decide_by_total_probs: False
weighted_sum: False